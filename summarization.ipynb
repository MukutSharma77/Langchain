{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Summarization Using Langchain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "open_api_key=\"sk-lGpacctDdtfs95bDRFJbjgmVZHrGI1X5PVtTlB2\"#Updating the API Key\n",
    "os.environ[\"OPENAI_API_KEY\"]=open_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Basic Prompt Summarization\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import(\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech=\"\"\"Each word forming an input sequence is transformed into a \n",
    "-dimensional embedding vector. \n",
    "Each embedding vector representing an input word is augmented by summing it (element-wise) to a positional encoding vector of the same \n",
    " length, hence introducing positional information into the input. \n",
    "The augmented embedding vectors are fed into the encoder block consisting of the two sublayers explained above. Since the encoder attends to all words in the input sequence, irrespective if they precede or succeed the word under consideration, then the Transformer encoder is bidirectional. \n",
    "The decoder receives as input its own predicted output word at time-step, \n",
    ".\n",
    "The input to the decoder is also augmented by positional encoding in the same manner done on the encoder side. \n",
    "The augmented decoder input is fed into the three sublayers comprising the decoder block explained above. Masking is applied in the first sublayer in order to stop the decoder from attending to the succeeding words. At the second sublayer, the decoder also receives the output of the encoder, which now allows the decoder to attend to all the words in the input sequence.\n",
    "The output of the decoder finally passes through a fully connected layer, followed by a softmax layer, to generate a prediction for the next word of the output sequence. \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_messages=[\n",
    "    SystemMessage(content='You are an expert assistant with expertize in summarizing speeches'),\n",
    "    HumanMessage(content=f'Please provide a short and concise summary of the following speech:\\n TEXT: {speech}')\n",
    "]\n",
    "\n",
    "llm=ChatOpenAI(model_name='gpt-3.5-turbo')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "248"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##total tokens\n",
    "llm.get_num_tokens(speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The speech explains the process of using Transformer architecture for natural language processing tasks. It describes how input words are transformed into embedding vectors and augmented with positional encoding for introducing positional information. The encoder block processes these augmented vectors bidirectionally, attending to all words in the input sequence. The decoder, on the other hand, predicts output words sequentially and uses positional encoding as well. The decoder block comprises three sublayers, including masking to prevent attending to future words and receiving encoder output for attention. The final output of the decoder goes through a fully connected layer and a softmax layer to generate predictions for the next word in the output sequence.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(chat_messages).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The speech discusses the process of transforming input words into embedding vectors and adding positional encoding to introduce positional information. It explains how the Transformer encoder is bidirectional, attending to all words in the input sequence. The decoder receives its own predicted output as input and also uses positional encoding. The decoder block includes three sublayers, with masking to prevent attending to succeeding words and receiving output from the encoder to attend to all input words. The decoder output passes through fully connected and softmax layers to predict the next word in the output sequence.\n"
     ]
    }
   ],
   "source": [
    "##get_summary\n",
    "print(llm(chat_messages).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Templates Text Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.chains import LLMChain\n",
    "from langchain import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "generic_template='''\n",
    "Write a summary of the following speech:\n",
    "Speech : `{speech}`\n",
    "Translate the precise summary to {language}.\n",
    "\n",
    "'''\n",
    "prompt=PromptTemplate(\n",
    "    input_variables=['speech','language'],\n",
    "    template=generic_template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nWrite a summary of the following speech:\\nSpeech : `Each word forming an input sequence is transformed into a \\n-dimensional embedding vector. \\nEach embedding vector representing an input word is augmented by summing it (element-wise) to a positional encoding vector of the same \\n length, hence introducing positional information into the input. \\nThe augmented embedding vectors are fed into the encoder block consisting of the two sublayers explained above. Since the encoder attends to all words in the input sequence, irrespective if they precede or succeed the word under consideration, then the Transformer encoder is bidirectional. \\nThe decoder receives as input its own predicted output word at time-step, \\n.\\nThe input to the decoder is also augmented by positional encoding in the same manner done on the encoder side. \\nThe augmented decoder input is fed into the three sublayers comprising the decoder block explained above. Masking is applied in the first sublayer in order to stop the decoder from attending to the succeeding words. At the second sublayer, the decoder also receives the output of the encoder, which now allows the decoder to attend to all the words in the input sequence.\\nThe output of the decoder finally passes through a fully connected layer, followed by a softmax layer, to generate a prediction for the next word of the output sequence. `\\nTranslate the precise summary to Hindi.\\n\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.format(speech=speech,language='Hindi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_prompt=prompt.format(speech=speech,language='Hindi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "267"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.get_num_tokens(complete_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "llm_chain=LLMChain(llm=llm,prompt=prompt)\n",
    "summary=llm_chain.run({'speech':speech,'language':'hindi'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'प्रत्येक शब्द एक इनपुट सीक्वेंस में एक -आयामी एम्बेडिंग वेक्टर में परिवर्तित होता है। प्रत्येक इनपुट शब्द को प्रस्तुत करने वाला एम्बेडिंग वेक्टर समान लंबाई के पोजीशनल एन्कोडिंग वेक्टर से जोड़कर उसे बढ़ाया जाता है, जिससे इनपुट में पोजीशनल जानकारी प्रस्तुत की जाती है। बढ़ाये गए एम्बेडिंग वेक्टर्स को दो उपलेयर वाले इन्कोडर ब्लॉक में भोजन किया जाता है। इन्कोडर सभी शब्दों को ध्यान देता है, चाहे वे शब्द जिसके तहत विचार में हो, पहले हों या बाद में, तो ट्रांसफार्मर इन्कोडर द्विदिशी है। डिकोडर अपने समय-स्टेप परिभाषित आउटपुट शब्द को इनपुट के रूप में प्राप्त करता है। डिकोडर को भी इनपुट पर पोजीशनल एन्कोडिंग जो इन्कोडर की तरह किया जाता है, से बढ़ाया जाता है। बढ़ाये गए डिकोडर इनपुट को डीकोडर ब्लॉक में तीन उपलेयरों में भोजन किया जाता है। पहले उपलेयर में मास्किंग लागू किया जाता है ताकि डिकोडर सभी उसके ध्यान देने वाले शब्दों को ध्यान न दे। दूसरे उपलेयर में, डिकोडर को इन्कोडर का आउटपुट भी मिलता है, जिससे डिकोडर को इनपुट सीक्वेंस में सभी शब्दों का ध्यान देने की अनुमति मिलती है। डिकोडर का आउटपुट अंततः एक पूर्ण संबंधित स्तर, एक सॉफ्टमैक्स स्तर के बाद, पारित होता है, जिससे अगले शब्द के लिए एक भविष्यवाणी उत्पन्न होती है।'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StuffDocumentChain Text Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# provide the path of  pdf file/files.\n",
    "pdfreader = PdfReader('Mukut_.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import Concatenate\n",
    "# read text from pdf\n",
    "text = ''\n",
    "for i, page in enumerate(pdfreader.pages):\n",
    "    content = page.extract_text()\n",
    "    if content:\n",
    "        text += content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.docstore.document import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [Document(page_content=text)]\n",
    "#docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0, model_name='gpt-3.5-turbo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.docstore.document import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = '''Write a concise and short summary of the following speech.\n",
    "Speech: `{text}`\n",
    "'''\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=['text'],\n",
    "    template=template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = load_summarize_chain(\n",
    "    llm,\n",
    "    chain_type='stuff',\n",
    "    prompt=prompt,\n",
    "    verbose=False\n",
    ")\n",
    "output_summary = chain.run(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mukut Sharma is a Data Scientist with expertise in programming languages, algorithms, data science, and various technologies. He has professional experience in companies like Syngene International Limited, MinionLabs, and RedTechno. He has worked on projects involving mass spectra prediction, machine state prediction, and resume screening using deep learning and machine learning models. Mukut Sharma is skilled in neural networks, data analysis, and model optimization.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarizing Large Documents Using Map Reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# provide the path of  pdf file/files.\n",
    "pdfreader = PdfReader('Mukut_.pdf')\n",
    "from typing_extensions import Concatenate\n",
    "# read text from pdf\n",
    "text = ''\n",
    "for i, page in enumerate(pdfreader.pages):\n",
    "    content = page.extract_text()\n",
    "    if content:\n",
    "        text += content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0, model_name='gpt-3.5-turbo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "929"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.get_num_tokens(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Splittting the text\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=10000, chunk_overlap=20)\n",
    "chunks = text_splitter.create_documents([text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = load_summarize_chain(\n",
    "    llm,\n",
    "    chain_type='map_reduce',\n",
    "    verbose=False\n",
    ")\n",
    "summary = chain.run(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mukut Sharma is a Data Scientist with expertise in programming languages, algorithms, and data science. He has experience working at Syngene International Limited, MinionLabs, and RedTechno, where he has developed neural network architectures, implemented machine learning models, and conducted exploratory data analysis. Mukut has worked on projects such as Mass Spectra Prediction, Machine State Prediction, and Resume Screening, utilizing deep learning models and machine learning algorithms. He is skilled in Python, TensorFlow, scikit-learn, and various data science tools and techniques.'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map Reduce With Custom Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks_prompt=\"\"\"\n",
    "Please summarize the below speech:\n",
    "Speech:`{text}'\n",
    "Summary:\n",
    "\"\"\"\n",
    "map_prompt_template=PromptTemplate(input_variables=['text'],\n",
    "                                    template=chunks_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_combine_prompt='''\n",
    "Provide a final summary of the entire Resume with these important points.\n",
    "Start the precise summary with an introduction and provide the\n",
    "summary in number points for the speech and also the skill candidate have.\n",
    "Speech: `{text}`\n",
    "'''\n",
    "final_combine_prompt_template=PromptTemplate(input_variables=['text'],\n",
    "                                             template=final_combine_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_chain = load_summarize_chain(\n",
    "    llm=llm,\n",
    "    chain_type='map_reduce',\n",
    "    map_prompt=map_prompt_template,\n",
    "    combine_prompt=final_combine_prompt_template,\n",
    "    verbose=False\n",
    ")\n",
    "output = summary_chain.run(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In summary, Mukut Sharma is a skilled Data Scientist with expertise in programming languages, algorithms, data science, and various technologies. He has professional experience in companies like Syngene International Limited, MinionLabs, and RedTechno, where he worked on challenging AI problems, model building, data analysis, and feature extraction. He has led projects such as Mass Spectra Prediction and Machine State Prediction, showcasing his proficiency in deep learning and machine learning models. Additionally, he has experience in resume screening using advanced techniques like BERT and Transformer. Mukut Sharma is a dedicated professional seeking mentorship opportunities to enhance his skills and knowledge in the field of data science.\\n\\nKey Points:\\n1. Skilled Data Scientist with expertise in programming languages, algorithms, data science, and various technologies.\\n2. Professional experience in companies like Syngene International Limited, MinionLabs, and RedTechno.\\n3. Led projects such as Mass Spectra Prediction and Machine State Prediction, showcasing proficiency in deep learning and machine learning models.\\n4. Experience in resume screening using advanced techniques like BERT and Transformer.\\n5. Seeking mentorship opportunities to enhance skills and knowledge in the field of data science.'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RefineChain For Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RefineDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"Mukut Sharma  \n",
      "mukkusharma77@gmail.com | +91 7665351716 | Bengaluru, India| LinkedIn  | GitHub  \n",
      "SKILLS  \n",
      "• Programming Languages and Libraries : Python ( scikit -learn, numpy, pandas, matplotlib, tensorflow, keras)  \n",
      "• Algorithms : Machine LearningAlgorithm (Linear Regression, Logistic Regression, K -Nearest Neighbors, Ensemble                                                                                               \n",
      "(Boosting, Bagging, Stacking) Random Forest, Gradient Boosting SVM), Clustering Algorithms (K-Means, DBSCAN),  \n",
      "Dimensionality Reduction Techniques (PCA, T -SNE, UMAP), NaturalLanguage Preprocessing (Word Embedding,  \n",
      "Transformer, BERT), DeepLearning Algorithm (Neural Network, Recurrent Neural Network, LSTM, CNN) , Lang chain, \n",
      "OpenAI   \n",
      "• Data Science & Miscellaneous Technologies: Data science pipeline (cleansing, wrangling,visualization,modeling, \n",
      "interpretation), Statistics, Time series, OOP, APIs, Github, Linux, Cloud (AWS), IoT (Raspeberry -pi) Excel  \n",
      "PROFESSIONALEXPERIENCE  \n",
      "Syngene International Limited  Bengaluru, IN Data Scientist  Augest2023 - Present  \n",
      "• Implementation of customized neural network architectures to optimize model performance  \n",
      "• Model building for multi -regression problems, specifically adept at handling scenarios with approximately 1000 input \n",
      "variables and 500 output variables.  \n",
      "• Implementation of machine learning and deep learning models derived from research papers and evaluating the results.  \n",
      "• Graph data analysis and proficient in evaluating neural network models using diverse graph embedding techniques for \n",
      "enhanced insights and performance optimization.  \n",
      "MinionLabs  Bengaluru, IN  \n",
      "Data Scientist  March 2022 - July 2023  \n",
      "• Work ed on challenging fundamental Artificial Intelligence problems in areas of Machine Learning, Deep Learning, Natural \n",
      "Language Processing  \n",
      "• Used machine learning tools to select features, create and optimize classifier.  \n",
      "• Process ed, clean ed, and validat ed the integrity of data to be used for analysis.  \n",
      "• Written automated scripts to extract data from different sources.  \n",
      "• Used statistical tools to identify, analyse, and interpret patterns and trends in large data sets that could aid in diagnosis and \n",
      "prediction.  \n",
      "RedTechno  Jaipur, IN  \n",
      "Data Analyistand Scientist  January2021 - February 2022  \n",
      "• Perform ed exploratory data analysis to uncover trends, patterns, and insights.  \n",
      "• Work ed on extracting meaningful features from diverse datasets to improve model accuracy.  \n",
      "• Utilize d tools like Matplotlib, Seaborn, or Tableau to present findings in a clear and understandable manner.  \n",
      "• Document ed the entire data science process, including data collection, preprocessing steps, model development, and \n",
      "evaluation metrics.  \n",
      "• Engage d in mentorship opportunities and seek guidance to enhance skills and knowledge in the field of data science\n",
      "  \n",
      "PROJECTSANDLEADERSHIP  \n",
      "Mass Spectra Prediction  Augest2023 - Present  \n",
      "• Developing a customized deep learning model to address a multi -regression problem predicting mass spectra from chemical \n",
      "compound structures.  \n",
      "• Utilized a diverse dataset of around 1 lakh compounds with 1000 input features, achieving a 0.81 median cosine similairty in \n",
      "predicting mass spectra patterns with 500 output dimensions.  \n",
      "• Extracted relevant features such as peak intensities, m/z ratios, and ion counts from 1000 input dimensions, resulting in a  0.25% improvement in model cosine simiarity with 500 output dimensions\n",
      "  \n",
      "• Integrated graph encoding techniques to capture relational information among compounds, enhancing prediction results\n",
      "  \n",
      "• Model Used : Neural Network with Cosine Similarity as a loss function  \n",
      "Machine State Prediction  March2022 - January2023  \n",
      "• Implemented various classification machine learning models to predict the operational status of machines. Consolidated the \n",
      "results from all models using a majority voting classifier to derive the final prediction.  \n",
      "• Handled a dataset of approximately 10 million records, leading preprocessing efforts, and conducting feature selection to \n",
      "enhance model efficiency.  \n",
      "• Developed a Python automated script to calculate the energy consumption of machines based on their operational status  \n",
      "• Model Used : Random Forest, Gradient Boosting, K -Means, Neural Network.  \n",
      "Resume Screening  March2021 - December 2022  \n",
      "• Successfully integrated the Hugging Face BERT model into the resume screening process,.  \n",
      "• Implemented an efficient system for extracting text from PDF resumes. Model Used : BERT, Transformer, Word Embedding \n",
      "Techniques\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "chain = load_summarize_chain(\n",
    "    llm=llm,\n",
    "    chain_type='refine',\n",
    "    verbose=True\n",
    ")\n",
    "output_summary = chain.run(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mukut Sharma is a Data Scientist with expertise in programming languages such as Python and algorithms including machine learning and deep learning. He has experience in data science pipeline, statistics, and various technologies. In his professional experience, he has worked on neural network architectures, machine learning models, and graph data analysis. He has also led projects in mass spectra prediction, machine state prediction, and resume screening using advanced techniques like deep learning and BERT model integration.'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
